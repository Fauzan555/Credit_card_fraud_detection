{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157348ba",
   "metadata": {},
   "source": [
    "# Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c94d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714cd436",
   "metadata": {},
   "source": [
    "# Loading the dataset and printing top 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565a46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sample:\n",
      "    id        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
      "1   1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
      "2   2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
      "3   3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
      "4   4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0 -0.130006  0.727159  ... -0.110552  0.217606 -0.134794  0.165959  0.126280   \n",
      "1 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469 -0.577395  0.190090   \n",
      "2 -0.095576 -0.261297  ... -0.005020  0.702906  0.945045 -1.154666 -0.605564   \n",
      "3 -0.065130 -0.205698  ... -0.146927 -0.038212 -0.214048 -1.893131  1.003963   \n",
      "4 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666  0.312561 -0.414116   \n",
      "\n",
      "        V26       V27       V28    Amount  Class  \n",
      "0 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
      "1  0.296503 -0.248052 -0.064512   6531.37      0  \n",
      "2 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
      "3 -0.515950 -0.165316  0.048424   5384.44      0  \n",
      "4  1.071126  0.023712  0.419117  14278.97      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\FAUZAN\\Downloads\\creditcard_2023.csv\\creditcard_2023.csv\")\n",
    "print(\"Dataset Sample:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f242f",
   "metadata": {},
   "source": [
    "# Spliting features and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6229877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: (568630, 30)\n",
      "Target Shape: (568630,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "print(\"Features Shape:\", X.shape)\n",
    "print(\"Target Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d507a",
   "metadata": {},
   "source": [
    "# Now doing training,testing, split and scalling the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65524f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e9e18",
   "metadata": {},
   "source": [
    "# Creating a dictionary of models, and then training and evalutating the each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f921abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Accuracy of Logistic Regression: 0.998\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56805    58]\n",
      " [  137 56726]]\n",
      "\n",
      "Training XGBoost...\n",
      "Accuracy of XGBoost: 1.000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56857     6]\n",
      " [   20 56843]]\n",
      "\n",
      "Training Decision Tree...\n",
      "Accuracy of Decision Tree: 1.000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56843    20]\n",
      " [   21 56842]]\n",
      "\n",
      "Training Extra Trees...\n",
      "Accuracy of Extra Trees: 1.000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56856     7]\n",
      " [   10 56853]]\n",
      "\n",
      "Training Naive Bayes...\n",
      "Accuracy of Naive Bayes: 0.932\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.94     56863\n",
      "           1       0.98      0.88      0.93     56863\n",
      "\n",
      "    accuracy                           0.93    113726\n",
      "   macro avg       0.94      0.93      0.93    113726\n",
      "weighted avg       0.94      0.93      0.93    113726\n",
      "\n",
      "Confusion Matrix:\n",
      " [[55854  1009]\n",
      " [ 6697 50166]]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', scale_pos_weight=(y == 0).sum() / (y == 1).sum(), random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy of {name}: {accuracy:.3f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    }\n",
    "    results[name] = accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f615ec",
   "metadata": {},
   "source": [
    "# Printing best performing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e318fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Performing Model is: Extra Trees with Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "best_model = max(results, key=results.get)\n",
    "print(\"\\n\\nBest Performing Model is:\", best_model, \"with Accuracy:\", f\"{results[best_model]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37c0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
